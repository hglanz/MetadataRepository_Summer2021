---
title: "Test"
author: "Sucheen Sundaram"
date: "6/21/2021"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
library(rvest)
library(Frost2021Package)
library(XML)
library(purrr)
library(bestpredictor)
```

```{r}
test_vest <- read_html("https://datahub.io/higorspinto/car-sales-world-annual")
description <- test_vest %>% html_nodes(".readable-width") %>% html_text()
description %>%
  pluck(2) %>%
  str_remove_all("\n")
```

```{r}
url <- "https://www.kaggle.com/kaggle/meta-kaggle"
scrape_rvest(url, ".dataset-header-v2__title")
```

```{r}
url <- "https://datadryad.org/stash/dataset/doi:10.5061/dryad.tqjq2bvxm"
cols <- scrape_rvest(url, ".c-sidebox__heading , .o-heading__level2")
data <- scrape_rvest(url, ".c-locations__data , .o-heading__level2+ p , .t-landing__text-wall p , #show_license p , .o-metrics__metric , .c-file-group , .c-file-group__summary")
df <- data.frame(matrix(ncol = length(cols), nrow = 0))
df <- rbind(df, data)
file_info_columns <- scrape_rvest(url, "#sidebar a")
file_info_data <- scrape_rvest(url, ".c-file-group__list div")
if(!identical(file_info_data, character(0))) {
  file_info <- data.frame(filename = file_info_columns, sizeMB = file_info_data)
}else{
  file_info <- c(NA)
}
if(!is.na(file_info)) {
  numbers <- parse_number(file_info$sizeMB)
count <- 1
for(i in file_info$sizeMB) {
  if("k" %in% i) { # if reported in kilobytes
    numbers[count] <- numbers[count]/1000
  }else if(!("MB" %in% i)) { # if reported in bytes
    numbers[count] <- numbers[count]/1000000
  }
  count <- count+1
}
file_info$sizeMB <- numbers
file_info <- nest(file_info)
}
names(df) <- cols[1:length(data)]
df$`Data Files` <- file_info
df$Methods <- scrape_rvest(url, ".t-landing__text-wall:nth-child(8) p:nth-child(1)")
df$Authors <- paste(scrape_rvest(url, ".o-metadata__author"), collapse = "; ")
df
```

```{r}
dataframe <- scrape_dryad("https://datadryad.org/stash/dataset/doi:10.5061/dryad.tqjq2bvxm")
pieces <- map_int(names(dataframe), ~str_split(dataframe[.x], " ") %>% pluck(1) %>% length())
dataframe[pieces != 2]
authors <- dataframe$Citation %>%
  str_split(" [(]") %>%
  pluck(1)
authors[1]
```

```{r}
# Iterate dryad
df <- data.frame(matrix(ncol = 5, nrow = 0))
count <- 0
for(i in 1:4169) {
  url <- paste("https://datadryad.org/search?page=", i, "&q=", sep = "")
  pg <- read_html(url)
  links <- html_attr(html_nodes(pg, "#documents a"), "href")
  links <- paste("https://datadryad.org", links, sep = "")
  links <- data.frame(links) %>% distinct()
  links <- links$links
  for(i in 1:length(links)) {
    df <- rbind(df, scrape_dryad(links[i]))
    print(nrow(df))
  }
  cat("\014")
}
df
```


```{r}
url <- "https://dataverse.harvard.edu/dataset.xhtml?persistentId=doi:10.7910/DVN/GPRRND"
name <- scrape_rvest(url, "#title")
  cols <- scrape_rvest(url, "#metrics-heading , th")
  data <- scrape_rvest(url, ".metrics-count-block , td")
  data <- data[data != "" & !str_detect(data, "dataDictionary")]
  df <- data.frame(matrix(ncol = length(cols), nrow = 0))
  df <- rbind(df, data)
  df$Citation <- scrape_rvest(url, ".citation-select")
  names(df) <- cols
  names(df)[6] <- "function"
  names(df)[5] <- "File Data"
  file_info_cols <- c("Name", "Downloads", "Variables", "Observations")
  file_info_names <- scrape_rvest(url, ".fileNameOriginal a")
  file_info_names <- file_info_names[file_info_names != ""]
  file_info <- data.frame(matrix(ncol = length(file_info_cols), nrow = length(file_info_names)))
  names(file_info) <- file_info_cols
  file_info <- cbind(file_info, file_info_names)
  file_info$Name <- file_info$file_info_names
  file_info <- file_info[, names(file_info) != "file_info_names"]
  downloads <- scrape_rvest(url, ".visible-lg-inline")
  variables <- scrape_rvest(url, ".unf-block span:nth-child(1)")
  observations <- scrape_rvest(url, ".unf-block span:nth-child(2)")
  if(!identical(downloads, character(0))) {
    while(length(downloads) != nrow(file_info)) {
      downloads <- append(downloads, NA)
    }
    file_info$Downloads <- parse_number(downloads)
  }else{
    file_info$Downloads <- NA
  }
  if(!identical(variables, character(0))) {
    while(length(variables) != nrow(file_info)) {
      variables <- append(variables, NA)
    }
    file_info$Variables <- parse_number(variables)
  }else{
    file_info$Variables <- NA
  }
  if(!identical(observations, character(0))) {
    while(length(observations) != nrow(file_info)) {
      observations <- append(observations, NA)
    }
    file_info$Observations <- parse_number(observations)
  }else{
    file_info$Observations <- NA
  }
  file_info <- nest(file_info, data = everything())
  df$`File Data` <- file_info
  df$Author <- scrape_rvest(url, "#metadata_author td")
  df$Name <- name
  df[, c("Name", "Description", "Subject", "Keyword", "File Data", "Deposit Date", "Author", "Depositor", "Dataset")]
```

```{r}
full_df <- data.frame(matrix(ncol = 9, nrow = 0))
for(i in 1:11395) {
  url <- paste("https://dataverse.harvard.edu/dataverse/harvard?q=&sort=dateSort&order=desc&page=", i, "&types=datasets", sep = "")
  pg <- read_html(url)
  links <- html_attr(html_nodes(pg, ".card-title-icon-block span a"), "href")
  links <- paste("https://dataverse.harvard.edu", links, sep = "")
  links <- data.frame(links) %>% distinct()
  links <- links$links
  for(j in links) {
    print(j)
    full_df <- rbind(full_df, scrape_harvard(j))
  }
}

html_attr(html_nodes(read_html("https://dataverse.harvard.edu/dataverse/harvard"), "a .card-title-icon-block"), "href")
```

```{r}
url <- "https://data.cdc.gov/Vaccinations/COVID-19-Vaccine-Distribution-Allocations-by-Juris/w9zu-fywh"
cols <- scrape_rvest(url, ".entry-description div")
df <- data.frame(matrix(ncol = length(cols), nrow = 0))
data <- scrape_rvest(url, ".dd")
```

```{r}
url <- "https://data.ca.gov/dataset/california-state-fleet"
desired_cols <- scrape_rvest(url, ".tags h3 , .module-heading , dt , .dataset-label")
cols <- scrape_rvest(url, ".module-heading , dt , .dataset-label , .tags h3")
data <- scrape_rvest(url, ".license span , .nav-item a , .module-shallow .heading , dd , .dataset-details , .well")
df <- data.frame(matrix(ncol = length(desired_cols), nrow = 0))
df <- rbind(df, data)
test <- scrape_cdph("https://data.ca.gov/dataset/covid-19-staff-data")
```

```{r}
full_df <- data.frame(matrix(ncol = ncol(test), nrow = 0))
names(full_df) <- names(test)
url <- "https://data.ca.gov/dataset?q=data&page=1"
pg <- read_html(url)
links <- html_attr(html_nodes(pg, "a"), "href")
links <- data.frame(links) %>%
  filter(str_detect(links, "/dataset/")) %>%
  distinct()
l <- vector(mode = "list", length = nrow(links))
for(i in links$links) {
  basic_link <- "https://data.ca.gov"
  data_link <- paste(basic_link, i, sep = "")
  full_df <- rbind(full_df, scrape_cdph(data_link))
}
full_df
```

```{r}
full_df <- data.frame(matrix(ncol = ncol(test), nrow = 0))
for(i in 1:119) {
  url <- paste("https://data.ca.gov/dataset?q=data&page=", i, sep = "")
  pg <- read_html(url)
  links <- paste("https://data.ca.gov", html_attr(html_nodes(read_html(url), ".dataset-heading a"), "href"), sep = "") %>% data.frame() %>% distinct()
  for(j in links$.) {
    data_link <- j
    tryCatch(expr = {
      full_df <- rbind(full_df, scrape_cdph(data_link))
    }, error = function(err) {
      NULL
    })
    print(nrow(full_df))
  }
}
clean_tag <- str_split(full_df$Tags, "[ ]+") %>%
  paste(sep = ";") %>%
  data.frame()
clean_tag <- str_remove_all(clean_tag$., c("c[{]", "[)]", "[\"]")) %>%
  data.frame()
```
```{r}
url <- "https://catalog.data.gov/dataset/2006-2012-math-test-results-district-all-students"
cols <- c(Frost2021Package::scrape_rvest(url, ".module-heading , .table-toggle-less tr+ tr .dataset-label , #access-use h3"), scrape_rvest(url, ".dataset-label"))
data <- c(scrape_rvest(url, ".module-narrow a"), scrape_rvest(url, ".table-toggle-less a , .dataset-details , td > span , #sec-dates td"))
data
cols <- cols %>% data.frame() %>% distinct()
cols <- cols$.
data <- data %>% data.frame() %>% rowid_to_column() %>% filter(rowid > 2)
data <- data$.
df <- data.frame(matrix(ncol = length(cols), nrow = 0))
df <- rbind(df, data)
names(df) <- cols
social <- scrape_rvest(url, ".social a")
string <- ""
for(i in social) {
  string <- paste(string, i, sep = " ")
}
string <- str_trim(string)
df$`Share on Social Sites` <- string
publisher <- scrape_rvest(url, "tr:nth-child(4) span")
publisher <- publisher[publisher != ""]
df$Publisher <- publisher
df$Contact <- scrape_rvest(url, ".contact a")
topics <- scrape_rvest(url, ".topics a")
topics <- topics %>% data.frame() %>% distinct()
topics <- topics$.
topics <- paste(topics, collapse = ", ")
df$Topics <- topics
df$`Terms of Use` <- scrape_rvest(url, ".terms a")[1]
access <- scrape_rvest(url, "#access-use strong , .access-public a")
access <- data.frame(access) %>% distinct()
access <- access$access
access <- str_remove_all(access, ":")
access <- paste(access, collapse = ", ")
df$`Access & Use Information` <- access

scrape_datagov("https://catalog.data.gov/dataset/2006-2011-nys-math-test-results-by-grade-citywide-by-race-ethnicity")
harvard <- scrape_harvard("https://dataverse.harvard.edu/dataset.xhtml?persistentId=doi:10.7910/DVN/VUAIMQ")
unnest(harvard$`File Data`)
```

```{r}
# Iterate data.gov
full_df <- data.frame(matrix(ncol = 24, nrow = 0))
for(i in 1:15391) {
  url <- paste("https://catalog.data.gov/dataset?page=", i, sep = "")
  pg <- read_html(url)
  links <- html_attr(html_nodes(pg, ".dataset-heading a"), "href")
  links <- paste("https://catalog.data.gov", links, sep = "")
  links <- links %>% data.frame() %>% distinct()
  links <- links$.
  for(j in links) {
    scraped <- scrape_datagov(j)
    print(j)
    for(k in names(scraped)) {
      if(!(k %in% names(full_df))) {
        scraped[k] <- c(NA)
      }
    }
    full_df <- rbind(full_df, scraped)
  }
  print(nrow(full_df))
}

full_df <- read.csv("./Data/cdph_scraped.csv")
```

```{r}
url <- "https://datahub.io/search"
pg <- read_html(url)
links <- html_attr(html_nodes(pg, "a"), "href")
links <- data.frame(links) %>% filter(str_detect(links, "/core/")) %>% distinct()
full_df <- data.frame(matrix(ncol = 7, nrow = 0))
for(i in links$links) {
  full_df <- rbind(full_df, scrape_datahub(paste("https://datahub.io", i, sep = "")))
}
full_df[, names(full_df) != "rowid"]
full_df$X.Size. <- parse_number(full_df$X.Size.)
scrape_datahub("https://datahub.io/core/finance-vix")
```

```{r}
# Zenodo
url <- "https://zenodo.org/record/5068660#.YOH7xhNKgTU"
name <- scrape_rvest(url, "h1")
author <- scrape_rvest(url, "h1 + p")
cols <- c(c("Name", "Authors"), scrape_rvest(url, ".addthis_32x32_style+ h4 , dt:nth-child(14) , dt:nth-child(12) , dt:nth-child(5) , dt:nth-child(1) , #collapse-stats tr:nth-child(6) td:nth-child(1) , #collapse-stats tr:nth-child(5) td:nth-child(1)"))
data <- scrape_rvest(url, "dd:nth-child(15) a , dd:nth-child(13) li , dd:nth-child(2) , #collapse-stats tr:nth-child(6) td:nth-child(2) , #collapse-stats tr:nth-child(5) td:nth-child(2) , h1+ p , h1 , #invenio-csl .ng-binding")
df <- data.frame(matrix(ncol = length(cols), nrow = 0))
df <- rbind(df, data)
keyword <- scrape_rvest(url, "dd:nth-child(6)")
if(!identical(keyword, character(0))) {
  keyword <- paste(keyword, collapse = ", ")
  df$`Keyword(s):` <- keyword
}else{
  df$`Keyword(s):` <- c(NA)
}
communities <- scrape_rvest(url, "dd:nth-child(13) li")
if(!identical(communities, character(0))) {
  communities <- paste(communities, collapse = ", ")
  df$`Communities:` <- communities
}else{
  df$`Communities:` <- c(NA)
}
file_info <- data.frame(Name = scrape_rvest(url, ".filename"), SizeMB = scrape_rvest(url, ".nowrap:nth-child(2)"))
numbers <- parse_number(file_info$SizeMB)
count <- 1
for(i in file_info$SizeMB) {
  if("kB" %in% i) {
    numbers[count] <- numbers[count]/1000
  }else if("GB" %in% i) {
    numbers[count] <- numbers[count]*1000
  }
}
file_info$SizeMB <- numbers
file_info <- file_info %>% nest(data = everything())
df$`File Info` <- file_info
names(df) <- cols

scrape_zenodo("https://zenodo.org/record/5045610#.YOJ1zRNKgTU")
```
